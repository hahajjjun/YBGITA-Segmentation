{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f4a0c6",
   "metadata": {},
   "source": [
    "# MultiResUNet : Rethinking the U-Net architecture for multimodal biomedical image segmentation\n",
    "**Reference** <br/>\n",
    "*[1] Ibtehaz, Nabil, and M. Sohel Rahman. \"MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation.\" Neural Networks 121 (2020): 74-87. <br/>\n",
    "[2] Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net: Convolutional networks for biomedical image segmentation.\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015. <br/>\n",
    "[3] Szegedy, Christian, et al. \"Going deeper with convolutions.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8892b9d9",
   "metadata": {},
   "source": [
    "### Related Works : U-Net\n",
    "- **Skip connections in U-Net** <br/>\n",
    "<img src=\"https://user-images.githubusercontent.com/75057952/161746257-f868e1f6-3f78-4b19-9b7e-bbbf910360c4.png\" width = \"500dp\"></img>\n",
    "- **Extensions of 2D U-Net to 3D U-Net**\n",
    "    - In particular, the two dimensional convolution, max pooling, transposed convolution operations were replaced by their three dimensional counterparts. \n",
    "    - In order to limit the number of parameters, the depth of the network was reduced by one. \n",
    "    - Moreover, the number of filters were doubled before thepooling layers to avoid bottlenecks. \n",
    "    - The original U-Net did not use batch normalization, however, they were experimented with in the 3D U-Net and astonishingly the results revealed that batch normalization may sometime even hurt the performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979555dd",
   "metadata": {},
   "source": [
    "### Motivations and current challenges\n",
    "**01. Variation of Scale in Medical Images**\n",
    "- segmenting cell necluei, organs, tumors etc. from images originating from various modalities.\n",
    "- objects of interest are of irregular and different scales.\n",
    "- e.g. scale of skin lesions can greatly vary in dermoscopy images! <br/>\n",
    "<img src = \"https://user-images.githubusercontent.com/75057952/161746274-9286abfb-15ed-47bb-b23d-34f0931e0e37.png\" width = \"500dp\"></img>\n",
    "- Inception Module?\n",
    "    - Remark on Inception\n",
    "        <img src = \"https://user-images.githubusercontent.com/75057952/161746285-c5d73d54-169b-45e1-aa88-c3c418474dbd.png\" width = \"400dp\"></img>\n",
    "    - Proposed Inception Module, called \"MultiRes Block\" : last figure\n",
    "        <img src = \"https://user-images.githubusercontent.com/75057952/161746297-5d6c6ea7-1328-4da4-bd11-d2b81195544e.png\"></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fc74cc5",
   "metadata": {},
   "source": [
    "**02. Probable Semantic Gap between the Corresponding Levels of Encoder-Decoder**\n",
    "- Novelty of U-Net\n",
    "    - introduction of shortcut connections between the corresponding layers before and after the max-pooling and the deconvolution layers respectively. \n",
    "    - This enables the network to propagate from encoder to decoder, the spatial information that gets lost during the pooling operation.\n",
    "-  Flaw of the skip connections?\n",
    "    - first shortcut connection bridges the encoder before the first pooling with the decoder after the last deconvolution operation\n",
    "    - does first layer of encoder & last layer of decoder match semantically? \n",
    "    - observae a possible semantic gap between the two sets of features being merged!\n",
    "    - propose to incorporate some convolutional layers along the shortcut connections.\n",
    "    - \"Res Path\" <br/>\n",
    "        -<img src=\"https://user-images.githubusercontent.com/75057952/161746308-07d83efc-00ae-4a9a-8a2a-55947e04eaa5.png\" width = \"600dp\"></img>\n",
    "\n",
    "**03. Overall Architecture**\n",
    "- MultiRes Block + Res Path <br/>\n",
    "    <img src =\"https://user-images.githubusercontent.com/75057952/161746322-7e635ab2-263d-4ed9-a6cf-b745254ca1b0.png\" width = \"600dp\"></img>\n",
    "- Architecture details <br/>\n",
    "    <img src = \"https://user-images.githubusercontent.com/75057952/161746332-bef12bff-61ff-4243-b4cc-c3387ea096ea.png\" width = \"600dp\"></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57543498",
   "metadata": {},
   "source": [
    "### Result\n",
    "**Quantitative Result** : MultiResUNet outperforms U-Net consistently<br/>\n",
    "    <img src = \"https://user-images.githubusercontent.com/75057952/161746343-65f6365b-fffe-4d30-b7d1-923ceb031660.png\" width = \"600dp\"></img>\n",
    "**Qualitative Result**\n",
    "- MultiResUNet Delineates Faint Boundaries Better<br/>\n",
    "    <img src = \"https://user-images.githubusercontent.com/75057952/161746352-b749ec14-8f06-46aa-9037-d06426a14b9a.png\" width = \"700dp\"></img>\n",
    "- MultiResUNet is More Immune to Perturbations(Artifacts, Noises) <br/>\n",
    "   <img src = \"https://user-images.githubusercontent.com/75057952/161746365-98f3162e-2637-40fd-ac21-3ca712ded725.png\" width = \"600dp\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8988dea",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a87094",
   "metadata": {},
   "source": [
    "```python\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "    else:\n",
    "        x = Activation(activation, name=name)(x)\n",
    "        return x\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    \n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    return x\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "\n",
    "    W = alpha * U\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) + int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3, activation='relu', padding='same')\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3, activation='relu', padding='same')\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    \n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    \n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model\n",
    "   \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    model = MultiResUnet(128, 128,3)\n",
    "    print(model.summary())\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
